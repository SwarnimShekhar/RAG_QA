{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56d21d10-12b6-46db-b54b-8361fd0d7a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_ollama import ChatOllama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "410fa809-f5c5-4f32-bab8-df3f36cf9923",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables from the .env file\n",
    "load_dotenv()\n",
    "\n",
    "groq_api_key = os.getenv('GROQ_API_KEY')\n",
    "pinecone_api_key = os.getenv('PINECONE_API_KEY')\n",
    "cohere_api_key = os.getenv('COHERE_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c109cfb-8a3c-4298-aea9-d87d8fec7e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_local = ChatOllama(model=\"mistral:instruct\")\n",
    "llm_groq = ChatGroq(\n",
    "            groq_api_key=groq_api_key,\n",
    "            model_name='mixtral-8x7b-32768'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0378b323-81e9-4977-8cca-70d57b7a58b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the PDF file\n",
    "pdf = PyPDF2.PdfReader(r\"C:\\Users\\swarn\\Desktop\\Swarnim_Shekhar_Resume.pdf\")\n",
    "pdf_text = \"\"\n",
    "for page in pdf.pages:\n",
    "    pdf_text += page.extract_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7eedf39-18ad-45b6-b888-bcbe01643e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the text into chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "texts = text_splitter.split_text(pdf_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc4f8113-f702-4fe7-8b1d-ba843e47108e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\swarn\\AppData\\Local\\Temp\\ipykernel_892\\2335156734.py:1: LangChainDeprecationWarning: The class `OllamaEmbeddings` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaEmbeddings``.\n",
      "  embeddings = OllamaEmbeddings(model=\"nomic-embed-text\")\n"
     ]
    }
   ],
   "source": [
    "embeddings = OllamaEmbeddings(model=\"nomic-embed-text\")\n",
    "\n",
    "r1 = embeddings.embed_documents(\n",
    "    texts\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e63d74c-bd4c-4ad9-9fce-cf5781b83a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone, ServerlessSpec\n",
    "\n",
    "pc = Pinecone(api_key=pinecone_api_key)\n",
    "\n",
    "pc.create_index(\n",
    "  name=\"rag-qa\",\n",
    "  dimension=768,\n",
    "  metric=\"cosine\",\n",
    "  spec=ServerlessSpec(\n",
    "    cloud=\"aws\",\n",
    "    region=\"us-east-1\"\n",
    "  )\n",
    ")\n",
    "\n",
    "index = pc.Index(\"rag-qa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c5a524f-f524-486c-b28e-372ffc792ede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done upserting...\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(texts)):\n",
    "    index.upsert([((str(i),r1[i],{\"text\":texts[i]}))])\n",
    "    \n",
    "print(\"done upserting...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b9cbc630-545b-481f-8b6c-cdb3836e984a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_query_embdedding(text):\n",
    "    embedding=embeddings.embed_query(text)\n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9a0088b1-1dea-4fd3-b4d1-43029a7d0676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: C:\\ProgramData\\sagemaker\\sagemaker\\config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: C:\\Users\\swarn\\AppData\\Local\\sagemaker\\sagemaker\\config.yaml\n"
     ]
    }
   ],
   "source": [
    "import cohere\n",
    "\n",
    "co = cohere.Client(cohere_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "65f34a31-44df-4818-a6fa-898f3a3a9df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "query=\"Can Swarnim be hired as a Gen AI engineer?\"\n",
    "\n",
    "question_embedding=get_query_embdedding(query)\n",
    "\n",
    "query_result = index.query(vector=question_embedding, top_k=5, include_metadata=True)\n",
    "similar_texts = []\n",
    "# Extract metadata from query result\n",
    "docs = {x[\"metadata\"]['text']: i for i, x in enumerate(query_result[\"matches\"])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3cf54e1d-a195-4dce-974a-999e8c5129d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rerank the documents\n",
    "rerank_docs = co.rerank(\n",
    "    model=\"rerank-english-v3.0\",\n",
    "    query=query, \n",
    "    documents=list(docs.keys()), \n",
    "    top_n=5, \n",
    "    return_documents=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0072da08-650d-4893-8047-e1fa7ca8ea31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SWARNIM SHEKHAR\\nData Science/ML\\n+91 7542898888 ⋄Pune, India\\nswarnim2302@gmail.com ⋄LinkedIn ⋄Github\\nOBJECTIVE\\nDedicated and result-driven aspiring Data Scientist in the final year of B.Tech in Computer Science Engineering.\\nEquipped with extensive hands-on experience from three internships, two of which focused on AI and Data Sci-\\nence. Proficient in Python, Machine Learning, Deep Learning, NLP, and Generative AI. Eager to contribute to the\\nadvancement of AI through innovative solutions and cutting-edge research.\\nEDUCATION\\nBachelor of Technology in Computer Science Engineering , MIT ADT University Expected 2025\\nSKILLS\\nTechnical Skills Machine Learning, Deep Learning, NLP, Python, Bert, GPT, Pandas, NumPy, Matplotlib,\\nSeaborn, Generative AI, Scikit-Learn, CNN, ANN, XGBoost, TensorFlow, Keras, Py-\\nTorch, NLTK, spaCy, Gensim, Transformers, SQL, C++, Analytics, GitHub\\nSoft Skills Analytical Thinking, Problem Solving, Team Collaboration, Communication, Team Lead-\\nership\\nEXPERIENCE',\n",
       " 'Torch, NLTK, spaCy, Gensim, Transformers, SQL, C++, Analytics, GitHub\\nSoft Skills Analytical Thinking, Problem Solving, Team Collaboration, Communication, Team Lead-\\nership\\nEXPERIENCE\\nProject Management Intern December 2023 - February 2024\\nForuppo Remote\\n•Spearheaded the development of a Minimalistic Product Development (MPD) framework to streamline product\\ndevelopment processes.\\n•Implemented the Minimum Viable Product (MVP) concept to rapidly iterate and validate product ideas, accel-\\nerating time-to-market.\\n•Utilized agile methodologies to iteratively build, test, and refine MVPs, fostering a culture of continuous im-\\nprovement and adaptability.\\nAI Engineer Intern November 2023 - January 2024\\nRadicalX Remote\\n•Led data preprocessing efforts, ensuring high-quality, clean, and properly formatted datasets for AI model\\ndevelopment.\\n•Developed and implemented robust data preprocessing pipelines, including data cleaning, feature engineering,\\nand normalization techniques.',\n",
       " '•Enhanced customer satisfaction and operational efficiency by addressing real-world logistics challenges through\\nsuccessful team collaboration and technical solutions alignment.\\nPROJECTS\\nReal-Time Language Translator (Link)\\nDeveloped a real-time language translation application using Python, integrating Vosk for speech recognition, Google\\nTranslate API for text translation, and gTTS for text-to-speech conversion.\\n•Technologies: Python, Vosk, Google Translate API, gTTS, Pygame\\nATS using Gemini (Link)\\nBuilt an application designed to evaluate resumes against job descriptions using artificial intelligence. The app\\nprovides feedback on match percentage and missing keywords.\\n•Technologies: Python, Streamlit, Google GenAI, PyPDF2, dotenv\\nLEADERSHIP\\nCodeChef SC MIT SOC\\nTechnical Team Lead\\n•Spearheaded the organization of multiple technical events and conducted instructional sessions, significantly\\nenhancing team proficiency and professional growth.',\n",
       " 'development.\\n•Developed and implemented robust data preprocessing pipelines, including data cleaning, feature engineering,\\nand normalization techniques.\\n•Collaborated closely with data scientists and machine learning engineers to understand project requirements\\nand refine preprocessing strategies accordingly.\\nData Science Intern May 2023 - July 2023\\nCode Nucleus Solutions Pune, Remote\\n•Led data extraction and preprocessing efforts for essential machine learning features, optimizing datasets for\\nanalysis.\\n•Conducted rigorous experimentation and selected the efficient XGBoost model for complex routing optimization,\\nenhancing delivery efficiency.\\n•Integrated the XGBoost model into the production system, facilitating delivery slot allocation and route opti-\\nmization.•Implemented a robust monitoring system, resulting in a 10 percent improvement in successful delivery rates.\\n•Enhanced customer satisfaction and operational efficiency by addressing real-world logistics challenges through',\n",
       " 'Technical Team Lead\\n•Spearheaded the organization of multiple technical events and conducted instructional sessions, significantly\\nenhancing team proficiency and professional growth.\\n•Developed team members into proficient speakers for future engagements through effective leadership and guid-\\nance.']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract reranked documents\n",
    "reranked_texts = [doc.document.text for doc in rerank_docs.results]\n",
    "reranked_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "138a6b16-8b20-447d-90e6-10fe40551631",
   "metadata": {},
   "outputs": [],
   "source": [
    "context=\" \".join(reranked_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "524d9ddc-a2d0-4031-b2c2-11867c1284f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Template = f\"Given the following context: {context}, generate a comprehensive and accurate response to the question: {query}. The response should include both paragraphs and bullet points where appropriate, ensuring that no important details from the context are omitted. Preserve all critical information and treat \\n as a newline character.\"  \n",
    "# Filling the template with the actual context and question.\n",
    "filled_template = Template.format(context=context, question=query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1ef1ebd6-743a-4b0d-b898-371c196118b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from groq import Groq\n",
    "\n",
    "client = Groq(\n",
    "    api_key=groq_api_key ,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2f47b420-2357-4939-8dd9-2a4caec89372",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": filled_template,\n",
    "        }\n",
    "    ],\n",
    "    model=\"mixtral-8x7b-32768\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a447aa69-1228-430c-b53f-5ec33bb99ecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided context, Swarnim can indeed be hired as a Gen AI (Generative AI) engineer. Here are the reasons supporting this conclusion:\n",
      "\n",
      "- Swarnim has hands-on experience in various AI and Data Science domains, including NLP (Natural Language Processing) and Generative AI, as stated in the context.\n",
      "- Swarnim's skill set encompasses several tools and libraries relevant to Gen AI, such as Python, NLP libraries (NLTK, spaCy, Gensim, Transformers), and SQL, demonstrating their proficiency in managing and processing data required for Gen AI model development.\n",
      "- Swarnim has worked on projects relevant to Gen AI, such as the \"Real-Time Language Translator\" project, which integrates speech recognition, text translation, and text-to-speech conversion. This project showcases Swarnim's ability to apply Gen AI techniques effectively.\n",
      "- Swarnim has experience as a Data Science Intern at Code Nucleus Solutions, where they led data extraction and preprocessing efforts, optimizing datasets for analysis. These skills are crucial in Gen AI projects for preparing and refining data to train models efficiently.\n",
      "- Swarnim's leadership roles, such as the Technical Team Lead at CodeChef SC MIT SOC, demonstrate their ability to collaborate with data scientists and machine learning engineers to understand project requirements and refine preprocessing strategies. This skill is essential for a Gen AI engineer as they often work in cross-functional teams.\n",
      "\n",
      "In summary, Swarnim's strong background in AI, Data Science, NLP, and familiarity with relevant tools and libraries make them a suitable candidate for a Gen AI engineer position. Their project experience, analytical thinking, problem-solving skills, and leadership roles further strengthen their candidacy.\n"
     ]
    }
   ],
   "source": [
    "print(chat_completion.choices[0].message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
